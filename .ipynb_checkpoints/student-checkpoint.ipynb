{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "\n",
    "- Students name:\n",
    "    - Billy Mwangi\n",
    "    - Lynne Mutwiri\n",
    "    - Sharon Kimani\n",
    "    - Susan Kanyora\n",
    "    - Kellen Kinya \n",
    "    - Derrick Wekesa\n",
    "- Student pace: full time\n",
    "- Scheduled project review date/time:\n",
    "- Instructor name:\n",
    "- Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import folium\n",
    "from datetime import datetime\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data= pd.read_csv('data/kc_house_data.csv')\n",
    "kc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting basic information about the data\n",
    "kc_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 21 columns:\n",
    "\n",
    "- 6 categorical and 15 numerical columns.\n",
    "- It has as a total of 21597 rows, the columns with a non null count of less than 21597 show existence of some missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting general summary statistics  on the data\n",
    "kc_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Involves manipulation, dropping or cleaning of data before it is used in order to ensure or enhance performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying and dealing with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(data):\n",
    "    \"\"\"A simple function to identify data has missing values\"\"\"\n",
    "    # identify the total missing values per column\n",
    "    # sort in order \n",
    "    miss = data.isnull().sum().sort_values(ascending = False)\n",
    "\n",
    "    # calculate percentage of the missing values\n",
    "    percentage_miss = (data.isnull().sum() / len(data)).sort_values(ascending = False)\n",
    "\n",
    "    # store in a dataframe \n",
    "    missing = pd.DataFrame({\"Missing Values\": miss, \"Percentage(%)\": percentage_miss})\n",
    "\n",
    "    # remove values that are missing \n",
    "    missing.drop(missing[missing[\"Percentage(%)\"] == 0].index, inplace = True)\n",
    "\n",
    "    return missing\n",
    "\n",
    "\n",
    "missing_data = missing_values(kc_data)\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The threshold on how to deal with missing values commonly used is 50% and also depends on the specific column. The percentages of missing values are very low for the specific columns so we can replace.\n",
    "- The percentage of the missing values for waterfront column(11.00%), view column(0.29%) and year renovated column(17.70%) are less than 50% , so we can replace them.\n",
    "- Checking the year renovated column we may assume the missing value is because the house was never renovated, maybe the house did not have a view or a waterfront also for the other two columns hence we can Fill them with zeros.\n",
    "- Since the missing values in the 3 columns are categorical and are a small percentage of the columns, replacing them with mode won`t skew the data nor give false conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_missing_values(data, columns):\n",
    "    missing = missing_values(data) # store the output of missing_values function\n",
    "    for col in columns:\n",
    "        if col in missing.index: # check if column has missing values\n",
    "            data[col] = data[col].fillna(data[col].mode()[0]) # fill missing values with mode\n",
    "    return data\n",
    "filling_missing_values(kc_data, ['waterfront','yr_renovated','view'])\n",
    "\n",
    "kc_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(data):\n",
    "    \"\"\"\n",
    "    A simple function to check for duplicates in a given dataset.\n",
    "    \"\"\"\n",
    "    duplicates = data.duplicated().sum()\n",
    "    return duplicates\n",
    "check_duplicates(kc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking duplicated id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_id = kc_data[kc_data.duplicated(subset=['id'], keep=False)]\n",
    "duplicates_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The id column shows the unique identifier for a house. \n",
    "* While there are duplicated ids of a house the prices and dates (of sale) of the house were different- hence why there were no duplicated rows- meaning the duplicated ids represent a house that was sold multiple times \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inconsistencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_value_counts(df):\n",
    "    for column in df.columns:\n",
    "        # Print the column name\n",
    "        print(\"Value counts for {} column:\".format(column))\n",
    "        # Print the value counts for the column\n",
    "        print(df[column].value_counts())\n",
    "        # Add a separator for clarity\n",
    "        print(\"=\"*30)\n",
    "\n",
    "print_value_counts(kc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inconsistent_data(df):\n",
    "    # Identify potential data inconsistencies\n",
    "    inconsistent_bedrooms = df[(df['bedrooms'] == 10) | (df['bedrooms'] == 11) | (df['bedrooms'] == 33)]\n",
    "    inconsistent_bathrooms = df[(df['bathrooms'] == 7) | (df['bathrooms'] == 8)]\n",
    "\n",
    "    # Concatenate the inconsistent data into a single DataFrame\n",
    "    inconsistent_data = pd.concat([inconsistent_bedrooms, inconsistent_bathrooms])\n",
    "inconsistent_data = find_inconsistent_data(kc_data)\n",
    "inconsistent_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square foot basement column has a placeholder value,?.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_holders(data, column):\n",
    "    inconsistent = data[data[column] == '?']\n",
    "    data[column].replace('?', 0.0, regex=False, inplace=True)\n",
    "\n",
    "place_holders(kc_data, 'sqft_basement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the number of bedrooms is greater than 10, the value in the sqft_living and sqft_lot a too little to match to that record meaning there is most likely an error in data entry. Therefore it`s best drop that column\n",
    "\n",
    "- It has 454 placeholder values, dropping the would mean loss of valuable data in the other columns\n",
    "\n",
    "- The placeholder would have most likely have been used to show that the house has no basement, we can therefore replace these placeholder values with the mode ie 0\n",
    "\n",
    "- The placeholder values constitute 2% of the column so imputing the data won't skew the data\n",
    "\n",
    "- We noticed that sqft_basement feature was categorica (object type) instead of numerical so we have to change it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the data type of the column because it contains numerical values\n",
    "kc_data['sqft_basement']=kc_data['sqft_basement'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers(data, columns):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(columns), figsize=(15,5))\n",
    "    for i, column in enumerate(columns):\n",
    "        # Use interquartile range (IQR) to find outliers for the specified column\n",
    "        q1 = data[column].quantile(0.25)\n",
    "        q3 = data[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        print(\"IQR for {} column: {}\".format(column, iqr))\n",
    "\n",
    "        # Determine the outliers based on the IQR\n",
    "        outliers = (data[column] < q1 - 1.5 * iqr) | (data[column] > q3 + 1.5 * iqr)\n",
    "        print(\"Number of outliers in {} column: {}\".format(column, outliers.sum()))\n",
    "\n",
    "        # Create a box plot to visualize the distribution of the specified column\n",
    "        sns.boxplot(data=data, x=column, ax=axes[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_outliers(kc_data, ['price', 'sqft_lot', 'sqft_above','sqft_lot','sqft_living15','sqft_lot15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(kc_data['price'])\n",
    "mean = kc_data['price'].mean()\n",
    "plt.axvline(x=mean, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has outliers but we cannot eliminate the outliers because they actually provide valuable information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for the distribution of individual columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data.hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for the location of our house sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by zipcode and calculate the mean latitude and longitude\n",
    "zipcode_data = kc_data.groupby('zipcode').agg({'lat': 'mean', 'long': 'mean'}).reset_index()\n",
    "\n",
    "# Create a map centered at the mean latitude and longitude of all the zipcodes\n",
    "m = folium.Map(location=[kc_data['lat'].mean(), kc_data['long'].mean()], zoom_start=10)\n",
    "\n",
    "# Add markers for each zipcode\n",
    "for _, row in zipcode_data.iterrows():\n",
    "    folium.Marker(location=[row['lat'], row['long']], popup=row['zipcode']).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking for the relationship between variables.\n",
    "- Our bivariate EDA involves checking for relationship between various features and the price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_col = 'price'\n",
    "for col in kc_data.columns:\n",
    "    if col != specific_col:\n",
    "        plt.scatter(kc_data[col], kc_data[specific_col])\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(specific_col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above visualizations we can see that the following features have the most linear relationship with price \n",
    "* sqft_living\n",
    "* sqft_above\n",
    "* sqft_living15\n",
    "* sqft_basement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the peak and low seasons for house sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_quarter =kc_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quarter_counts(data):\n",
    "    dates = pd.to_datetime(data['date'], format='%m/%d/%Y')\n",
    "    dates_column = dates.dt.quarter\n",
    "    # get the counts for each quarter\n",
    "    quarter_counts = dates_column.value_counts()\n",
    "    quarter_counts.plot.bar()\n",
    "    # plot a bar chart of the quarter counts\n",
    "    plt.title('Counts of Sales by Quarter')\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "plot_quarter_counts(kc_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "\n",
    "- The highest number of house sales are made in the second quarter of the year (Q2: April 1 - June 30) which fall in the Spring season\n",
    "- The lowest number of house sales are made in the first quarter of the year (Q1: January 1 - March 31) which fall mostly in the Winter season\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took the features with the most linear relationship to the price and then visualize them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(kc_data['sqft_living'], kc_data['price'], label='sqft_living')\n",
    "plt.scatter(kc_data['sqft_above'], kc_data['price'], label='sqft_above')\n",
    "plt.xlabel('Square footage')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Price vs Square footage')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data points of sqft_living and sqft_above lie close together and they show a strong positive linear relationship with the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(kc_data['sqft_living'], kc_data['price'], label='sqft_living')\n",
    "plt.scatter(kc_data['sqft_above'], kc_data['price'], label='sqft_above')\n",
    "plt.scatter(kc_data['sqft_living15'], kc_data['price'], label='sqft_living15')\n",
    "plt.scatter(kc_data['sqft_basement'], kc_data['price'], label='sqft_basement')\n",
    "plt.xlabel('Square footage')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Price vs Square footage')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data points of sqft_living, sqft_above, sqft_living15 and sqft_basement lie close together and they show a strong positive linear relationship with the price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the year from date sold \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting date column from categorical (object) to numerical (int64)\n",
    "kc_data['date'] = pd.to_datetime(kc_data['date'], format='%m/%d/%Y')\n",
    "#Extract the year and create a new column\n",
    "kc_data['year'] = kc_data['date'].dt.year\n",
    "kc_data.drop('date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a new column named Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date (year) of the sale and the year built can be used to obtain the age of the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new column age\n",
    "kc_data['age']= kc_data['year']-kc_data['yr_built']\n",
    "kc_data['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since we have obtained the age of the house we can drop the year and yr_built columns.\n",
    "* We drop the id of the house since it`s not in the modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the columns year, yr_built, id\n",
    "kc_data.drop(['year','yr_built', 'id'],axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data doesn't have missing values, duplicates or placeholder values and all the columns are in their correct datatypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = kc_data.corr()\n",
    "fig, ax = plt.subplots(figsize=(12,12))   # Set the figure size to 12 inches by 12 inches\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax)\n",
    "plt.title('Correlation Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does each independent variable relate with the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=kc_data.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "df['pairs'] = list(zip(df.level_0, df.level_1))\n",
    "\n",
    "# set index to pairs\n",
    "df.set_index(['pairs'], inplace = True)\n",
    "\n",
    "#d rop level columns\n",
    "df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# rename correlation column as cc rather than 0\n",
    "df.columns = ['cc']\n",
    "\n",
    "# drop duplicates. This could be dangerous i\n",
    "df[(df.cc>.75) & (df.cc <1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above pairs are the most highly collerated to each other.\n",
    "* Therefore adding all those variables will bring about multicollinearity in the model so we will drop some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data.drop(['sqft_above', 'sqft_living15', 'bathrooms'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data.drop(['lat', 'long', 'zipcode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data['yr_renovated']= kc_data['yr_renovated'].apply(lambda x: 1 if x>0 else 0 )\n",
    "kc_data['yr_renovated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding waterfront,view and condition\n",
    "kc_transform = pd.get_dummies(kc_data, columns=[\"waterfront\",'view','condition'])\n",
    "kc_transform = kc_transform.drop([\"condition_Poor\",'view_NONE','waterfront_NO'], axis=1)\n",
    "kc_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reference categories for view will be None, for waterfront will be No and for condition will be poor condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert grade column to numeric using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "kc_transform['grade'] = label_encoder.fit_transform(kc_transform['grade'])\n",
    "kc_transform['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_transform.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_transform.corr()['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sqft_living has the strongest positive correlation with price\n",
    "* Sqft_basement, bedrooms and view_EXCELLENT has low positive correlation with price\n",
    "* Grade, Age and condition have weak negative correlation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model will be that of price and the variable that is highly correlated to it\n",
    "* We will use an ```alpha``` of ```0.05```\n",
    "* We used forward filling to determine the best model\n",
    "\n",
    "We choose to use RMSE as our error based metric because:\n",
    "\n",
    "* RMSE gives more weight to larger errors than smaller errors.\n",
    "* RMSE is more sensitive to outliers than other metrics such as MAE\n",
    "* It is commonly used to compare different models and choose the best performing one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline model\n",
    "X= kc_transform[['sqft_living']]\n",
    "y=kc_transform['price']\n",
    "model=sm.OLS(y, sm.add_constant(X))\n",
    "results=model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model \n",
    "pred_model = LinearRegression()\n",
    "pred_model.fit(X, y)\n",
    "\n",
    "# predict the values of the dependent variable \n",
    "y_pred = pred_model.predict(X)\n",
    "\n",
    "# calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model is that of square foot living and price since square foot living has the highest correlation to price. The model is statistically significant since the F-statistic p-value is less than 0.05 and it explains 49.3% of the total variation of price.\n",
    "\n",
    "* An increase of 1 square foot in the living area leads to a price increase of approximately 281.\n",
    "\n",
    "* The model is off by 261656 in price.\n",
    "\n",
    "Let's add more predictors to improve the accuracy of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= kc_transform[['sqft_living','sqft_basement']]\n",
    "y=kc_transform['price']\n",
    "model=sm.OLS(y, sm.add_constant(X))\n",
    "results=model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model \n",
    "pred_model1 = LinearRegression()\n",
    "pred_model1.fit(X, y)\n",
    "\n",
    "# predict the values of the dependent variable \n",
    "y_pred = pred_model1.predict(X)\n",
    "\n",
    "# calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model is that of square foot living , square foot basement and price. \n",
    "* The model is statistically significant since the F-statistic p-value is less than 0.05\n",
    "* The model explains 49.3% of the total variation of price same as the other model showing that adding the square foot basement doesn't improve the model.\n",
    "* The two coefficients are statistically significant since their t-statistic p values are less than 0.05.\n",
    "\n",
    "* The model is off by $261525 in price which has reduced from the previous model. \n",
    "* An increase of 1 square foot in the living area leads to an increase of approximately $276.6 in price.\n",
    "* An increase of 1 square foot in the basement area leads to an increase of approximately $20.7 in price. \n",
    "\n",
    "Let's add more predictors to improve the accuracy of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= kc_transform[['sqft_living','sqft_basement','bedrooms','view_EXCELLENT']]\n",
    "y=kc_transform['price']\n",
    "model=sm.OLS(y, sm.add_constant(X))\n",
    "results=model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model \n",
    "pred_model2 = LinearRegression()\n",
    "pred_model2.fit(X, y)\n",
    "\n",
    "# predict the values of the dependent variable \n",
    "y_pred = pred_model2.predict(X)\n",
    "\n",
    "# calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model is that of square foot living , square foot basement, bedrooms, view_EXCELLENT and price. \n",
    "* The model is statistically significant since the p-value is less than 0.05 and it explains 54% of the total variation of price which has improved from the previous models making our model more accurate.\n",
    "* The coefficients are statistically significant since their pvalues are less than 0.05.\n",
    "\n",
    "* The model is off by $249321 in price which has reduced from the previous models. \n",
    "* An increase of 1 square foot in the living area leads to an increase of approximately $296.11 in price. \n",
    "* An increase of 1 square foot in the basement area leads to an increase of approximately $12.85 in price. \n",
    "* An increase of 1 bedroom leads to an decrease of approximately $56090 in price. \n",
    "* A house with an excellent view compared to that with no view leads to an increase of $552500 in price.\n",
    "\n",
    "Let's add more predictors to improve the accuracy of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= kc_transform[['sqft_living','sqft_basement','bedrooms','view_EXCELLENT', 'waterfront_YES','floors']]\n",
    "y=kc_transform['price']\n",
    "model=sm.OLS(y, sm.add_constant(X))\n",
    "results=model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model \n",
    "pred_model3 = LinearRegression()\n",
    "pred_model3.fit(X, y)\n",
    "\n",
    "# predict the values of the dependent variable \n",
    "y_pred = pred_model3.predict(X)\n",
    "\n",
    "# calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model is that of square foot living , square foot basement, bedrooms, view_EXCELLENT, waterfront_yes ,floors and price. \n",
    "* The model is statistically significant since the F-statistic p-value is less than 0.05 and it explains 55% of the total variation of price which has improved from the previous models making our model more accurate.\n",
    "* The coefficients are statistically significant since their t-statistic p values are less than 0.05.\n",
    "\n",
    "* The model is off by $246200 in price which has reduced from the previous models. \n",
    "* An increase of 1 square foot in the living area leads to an increase of approximately $288.76 in price. \n",
    "* An increase of 1 square foot in the basement area leads to an increase of approximately $23.33 in price. \n",
    "* An increase of 1 bedroom leads to an decrease of approximately $49460 in price. \n",
    "* A house with an excellent view compared to that with no view leads to an increase of an $345500 in price. \n",
    "* A house on a waterfront compared to that not on a waterfront leads to an increase in 544500 542500 shillings in price. \n",
    "* An increase of one more floor in a house leads to an increase of $16970 in price.\n",
    "\n",
    "Let's add more predictors to improve the accuracy of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= kc_transform[['sqft_living','sqft_basement','bedrooms','view_EXCELLENT', \n",
    "                 'waterfront_YES','floors','grade','age','condition_Fair']]\n",
    "y=kc_transform['price']\n",
    "model=sm.OLS(y, sm.add_constant(X))\n",
    "results=model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model \n",
    "pred_model4 = LinearRegression()\n",
    "pred_model4.fit(X, y)\n",
    "\n",
    "# predict the values of the dependent variable \n",
    "y_pred = pred_model4.predict(X)\n",
    "\n",
    "# calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On adding the variables that are lowly correlated to price , the model's accuracy improved to 59.9% and the RMSE has reduced to 232835.\n",
    "* So let's try adding all the variables and see how the model performs.\n",
    "* Before adding square foot lot and lot15 we need to log transform them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_copy= kc_transform.copy()\n",
    "\n",
    "kc_copy[\"log(sqft_lot)\"] = np.log(kc_copy[\"sqft_lot\"])\n",
    "\n",
    "# Visually inspect raw vs. transformed values\n",
    "kc_copy[[\"sqft_lot\", \"log(sqft_lot)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(7,3))\n",
    "ax1.hist(kc_copy[\"sqft_lot\"])\n",
    "ax1.set_xlabel(\"sqft_lot\")\n",
    "ax2.hist(kc_copy[\"log(sqft_lot)\"], color=\"orange\")\n",
    "ax2.set_xlabel(\"log(sqft_lot)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_copy[\"log(sqft_lot15)\"] = np.log(kc_copy[\"sqft_lot15\"])\n",
    "\n",
    "# Visually inspect raw vs. transformed values\n",
    "kc_copy[[\"sqft_lot15\", \"log(sqft_lot15)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(7,3))\n",
    "ax1.hist(kc_copy[\"sqft_lot15\"])\n",
    "ax1.set_xlabel(\"sqft_lot15\")\n",
    "ax2.hist(kc_copy[\"log(sqft_lot15)\"], color=\"orange\")\n",
    "ax2.set_xlabel(\"log(sqft_lot15)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_copy.drop(['sqft_lot15',\"sqft_lot\"],axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = kc_transform.drop('price', axis=1)\n",
    "y = kc_transform['price']\n",
    "X = sm.add_constant(X)\n",
    "model1 = sm.OLS(y, X)\n",
    "results1 = model1.fit() \n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "pred_model5 = LinearRegression()\n",
    "pred_model5.fit(X, y)\n",
    "\n",
    "# predict the values of the dependent variable\n",
    "y_pred = pred_model5.predict(X)\n",
    "\n",
    "# calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = kc_copy.drop('price', axis=1)\n",
    "y = kc_copy['price']\n",
    "X = sm.add_constant(X)\n",
    "model1 = sm.OLS(y, X)\n",
    "results1 = model1.fit() \n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model \n",
    "pred_model6 = LinearRegression()\n",
    "pred_model6.fit(X, y)\n",
    "\n",
    "# predict the values of the dependent variable \n",
    "y_pred = pred_model6.predict(X)\n",
    "\n",
    "# calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why transform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first model is without the log transformation and the second one is after the log transformation. The second one is better since it explains 61.7% of the total variation in price compared to the first model that explains 61% of the variation in price . \n",
    "* The RMSE of the second model is also lower thus we'll use the second model. \n",
    "* Interpreting the second model, some variables are not significant since their p-value is more than 0.05 but we can't drop them because that will mean we'll use them as a reference category and we already have a reference category.\n",
    "\n",
    "This is our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "* The model is that of bedrooms, sqft_living, floors, grade,sqft_basement,yr_renovated, age, waterfront_YES, view_AVERAGE,view_EXCELLENT, view_FAIR, view_GOOD, condition_Average,condition_Fair, condition_Good, condition_Very Good,log(sqft_lot), log(sqft_lot15) and price. \n",
    "* The model is statistically significant since the F-statistic p-value is less than 0.05 and it explains 61.7%% of the total variation of price which has improved from the previous models making our model more accurate.\n",
    "* Most of the predictor variables are statistically significant apart from condition fair and condition average. \n",
    "\n",
    "* The model is off by $227171 in price which has reduced from the previous models. \n",
    "* An increase of 1 square foot in the living area leads to an increase of approximately $308.73 in price. \n",
    "* An increase of 1 square foot in the basement area leads to a decrease of approximately $36.72 in price. \n",
    "* An increase of 1 bedroom leads to an decrease of approximately $409200 in price.\n",
    "* A house graded higher by one unit leads to a decrease of approximately $19990 in price.\n",
    "* An increase of 1 year in the age of the house leads to an increase of approximately $2154.77 in price.\n",
    "* Renovating a house leads to an increase of your price by $63110 in price.\n",
    "* A house on a waterfront compared to that not on a waterfront leads to an increase in $502500 in price.\n",
    "* A house with an average view compared to that with no view leads to an increase of an $90700 in price.\n",
    "* A house with an excellent view compared to that with no view leads to an increase of an $340600 in price.\n",
    "* A house with a good view compared to that with no view leads to an increase of an $159900 in price. \n",
    "* A house with a fair view compared to that with no view leads to an increase of an $140200 in price. \n",
    "* An increase of one more floor in a house leads to an increase of $31440 in price.\n",
    "* A house in an average condition compared to that in poor condition leads to an increase of an $80020 in price. \n",
    "* A house in fair condition compared to that in poor condition leads to an increase of an $41180 in price.\n",
    "* A house in good condition compared to that in poor condition leads to an increase of an $103100 in price.\n",
    "* A house in very good condition compared to that in poor condition leads to an increase of an $138300 in price.\n",
    "* For each increase of 1% in square foot lot there is decrease of $386.8 in price. \n",
    "* For each increase of 1% in square foot lot15 there is decrease of $135.6 in price. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure( figsize=(40,40))\n",
    "sm.graphics.plot_partregress_grid(results1, exog_idx=list(X.columns.values),fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On visualizing the partial regression plots we can see that the predictor variables have a linear relationship with price thus concluding that they are beneficial to our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in kc_copy:\n",
    "    kc_copy[col]=(kc_copy[col]-kc_copy[col].mean())/kc_copy[col].std()\n",
    "    \n",
    "X = kc_copy.drop('price', axis=1)\n",
    "y = kc_copy['price']\n",
    "X = sm.add_constant(X)\n",
    "model1 = sm.OLS(y, X)\n",
    "results1 = model1.fit() \n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1.params.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that square foot living has the highest influence on the price of the house. \n",
    "* The variables that have a major influence on the price of the house are; square foot living, age of the house,good condition of the house,if the house is on a waterfront and has an excellent view.\n",
    "* The variables that has the least influence on the price of the house are; grade,number of bedrooms,sqft lot,sqft basement and sqft lot 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The variables that have a major influence on the price of the house are; square foot living, age of the house,good condition of the house,if the house is on a waterfront and has an excellent view.\n",
    "* The variables that has the least influence on the price of the house are; grade,number of bedrooms,sqft lot,sqft basement and sqft lot 15.\n",
    "\n",
    "We can also see that:\n",
    "\n",
    "- The highest number of house sales are made in the second quarter of the year (Q2: April 1 - June 30) which fall in the Spring season\n",
    "- The lowest number of house sales are made in the first quarter of the year (Q1: January 1 - March 31) which fall mostly in the Winter season\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Revonate their house since this increases the value of the house\n",
    "* Ensure that the houses are in good condition before putting it into the market for sale\n",
    "* Increase square footage of living space \n",
    "* Put up their houses for sale in peak season-Spring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reducing noise in the data to improve the accuracy of our model. \n",
    "* Additionally investigate certain features, such as constructional/architectural values of the house, to see what trends we could discern from that. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
